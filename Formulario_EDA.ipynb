{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Proceso: preparación Transaccional + EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "letter = string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Importar Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar filas y columnas vacías ENTREMEDIO de la tabla importada (agregar dropna después de importar el excel)\n",
    "\n",
    "def importar_excel(nombre_excel, xlsx=True):\n",
    "    \n",
    "    x = pd.ExcelFile(nombre_excel)\n",
    "    y = x.sheet_names\n",
    "    dict = {}\n",
    "    for i, j in zip(range(0,len(y)),y):\n",
    "        dict.update({i : j})\n",
    "    \n",
    "    hoja = int(input(f'¿Cuál de las siguientes hojas quieres importar? (Selecciona el número de la hoja): \\n {dict} \\n '))\n",
    "    \n",
    "    \n",
    "    if xlsx is True:   \n",
    "        nombre_csv = nombre_excel[0:-5]\n",
    "    else: \n",
    "        nombre_csv = nombre_excel[0:-4]\n",
    "        \n",
    "    df1 = pd.read_excel(nombre_excel, sheet_name=hoja)\n",
    "    \n",
    "    def get_first_row(df):\n",
    "        for index, row in df.iterrows():\n",
    "            if not row.isnull().values.all():\n",
    "                if index != 0:\n",
    "                    return index + 1\n",
    "                else:\n",
    "                    return index\n",
    "            \n",
    "    def get_start_column(df):\n",
    "        for i, column in enumerate(df.columns):\n",
    "            if df[column].first_valid_index():\n",
    "                return letter[i]\n",
    "            elif df.iloc[0].first_valid_index():\n",
    "                return 'A'\n",
    "    \n",
    "    def get_last_column(df):\n",
    "        for i, column in enumerate(df.columns):\n",
    "            if get_start_column(df):\n",
    "                if len(df.columns)-i <=25:\n",
    "                    return letter[len(df.columns) - i]\n",
    "                else:\n",
    "                    return f\"A{letter[(len(df.columns) - i)-25]}\"\n",
    "\n",
    "    def usecols(df):\n",
    "        start = get_start_column(df)\n",
    "        end = get_last_column(df)\n",
    "        return f\"{start}:{end}\"\n",
    "\n",
    "    df = pd.read_excel(nombre_excel, sheet_name=hoja, header=get_first_row(df1), usecols=usecols(df1))\n",
    "    archivo_csv = df.to_csv(f\"{nombre_csv}.csv\",\n",
    "                            index = None,\n",
    "                            header = True)\n",
    "    archivo_csv = pd.DataFrame(pd.read_csv(f\"{nombre_csv}.csv\"))\n",
    "    \n",
    "    return archivo_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ver valores únicos por campo, nulos y no-nulos, formato, máximo y mínimo.\n",
    "# Además un resumen estadístico con los rangos y distribución de la data\n",
    "\n",
    "def overview(dataframe):\n",
    "    \n",
    "    data_resumen = {'Valores Unicos':dataframe.nunique(),'No-Nulos': dataframe.notnull().sum(), \n",
    "                    'Nulos': dataframe.isnull().sum(), 'Formato': dataframe.dtypes, 'Min': dataframe.min(),\n",
    "                    'Max': dataframe.max()}\n",
    "    resumen = pd.DataFrame(data=data_resumen)\n",
    "    print(dataframe.describe())\n",
    "    \n",
    "    return resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Esquema Transaccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una lista con los índices del dataframe junto con los nombres de los campos\n",
    "# para armar dataframe nuevo (transaccional)\n",
    "\n",
    "def esquema_transaccional(df,index_campos,_1='fecha', _2='id_cliente', _3='nro_transaccion', \n",
    "                          _4='sku',_5='cantidad', _6='unidadmedida', _7=None, _8=None, _9=None, _10=None):\n",
    "\n",
    "    campos = df.columns.values[index_campos].tolist()\n",
    "    columnas = [_1,_2,_3,_4,_5,_6,_7,_8,_9,_10]\n",
    "    transaccional = []\n",
    "\n",
    "    for (campo,columna) in zip(campos,columnas):\n",
    "        df0 = df.rename(columns=dict(zip(campos, columnas)))\n",
    "        transaccional.append(columna)\n",
    "        \n",
    "    df1 = df0[transaccional]\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulos(df):\n",
    "\n",
    "    is_NaN = df.isnull()\n",
    "    row_has_NaN = is_NaN.any(axis=1)\n",
    "    rows_with_NaN = df[row_has_NaN]\n",
    "    n_nulos = len(rows_with_NaN)\n",
    "    \n",
    "    if n_nulos > 0:\n",
    "        \n",
    "        print(f'¡Se han encontrado {n_nulos} registros que contienen valores nulos!\\n')\n",
    "        \n",
    "        dict = {'Analizar': 1, 'Borrar': 0}\n",
    "        answer = int(input(f'¿Qué quieres hacer con estos registros? (Escribe el número de la respuesta): \\n {dict} \\n '))\n",
    "        \n",
    "        if answer == 0:\n",
    "            df.dropna(inplace=True)\n",
    "            return df\n",
    "        \n",
    "        else:\n",
    "            print(rows_with_NaN.nunique())\n",
    "            return rows_with_NaN\n",
    "        \n",
    "    else:\n",
    "        print(f'¡No se encontraron registros nulos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicados(df):\n",
    "    \n",
    "    duplicateDFRow = df[df.duplicated()]\n",
    "    n_duplicados = len(duplicateDFRow)\n",
    "    \n",
    "    if n_duplicados > 0:\n",
    "\n",
    "        print(f'¡Se han encontrado {n_duplicados} registros duplicados!')\n",
    "        dict = {'Analizar': 1, 'Borrar': 0}\n",
    "        answer = int(input(f'¿Qué quieres hacer con estos registros? (Escribe el número de la respuesta): \\n {dict} \\n '))\n",
    "        \n",
    "        if answer == 0:\n",
    "            df1 = df\n",
    "            df1.drop_duplicates(keep='first',inplace=True)\n",
    "            return df1\n",
    "        \n",
    "        else:\n",
    "            print(duplicateDFRow.nunique())\n",
    "            return duplicateDFRow\n",
    "        \n",
    "    else:\n",
    "        print(f'¡No se encontraron registros duplicados!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Columna Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_fecha(df,columna_fecha, texto=False):\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Opción para casos donde la fecha esté separada en columnas de año y mes, para armar columna mensual\n",
    "    if texto == True:\n",
    "        month = []\n",
    "        for i in range (0,len(df)):\n",
    "            mes = df.loc[df.index[i], 'mes']\n",
    "    \n",
    "            if mes == 'ENERO':\n",
    "                mes_i = '01'\n",
    "            elif mes == 'FEBRERO':\n",
    "                mes_i = '02'\n",
    "            elif mes == 'MARZO':\n",
    "                mes_i = '03'\n",
    "            elif mes == 'ABRIL':\n",
    "                mes_i = '04'\n",
    "            elif mes == 'MAYO':\n",
    "                mes_i = '05'\n",
    "            elif mes == 'JUNIO':\n",
    "                mes_i = '06'\n",
    "            elif mes == 'JULIO':\n",
    "                mes_i = '07'\n",
    "            elif mes == 'AGOSTO':\n",
    "                mes_i = '08'\n",
    "            elif mes == 'SEPTIEMBRE':\n",
    "                mes_i = '09'\n",
    "            elif mes == 'OCTUBRE':\n",
    "                mes_i = '10'\n",
    "            elif mes == 'NOVIEMBRE':\n",
    "                mes_i = '11'\n",
    "            elif mes == 'DICIEMBRE':\n",
    "                mes_i = '12'\n",
    "            else:\n",
    "                mes_i = mes\n",
    "                \n",
    "            month.append(mes_i)\n",
    "    \n",
    "        df['mes'] = month\n",
    "        df['año'] = df['año'].apply(str)\n",
    "        \n",
    "        # Se especifica si existe un campo con el día para usarlo en la construcción de la fecha, o se deja \"01\" por defecto\n",
    "        if 'dia' in df.columns:\n",
    "            df[columna_fecha] = df['año'] + '-' + df['mes'] + df['dia'].apply(str)\n",
    "        else:\n",
    "            df[columna_fecha] = df['año'] + '-' + df['mes'] + '-01'\n",
    "    \n",
    "    # Flujo estándar de la función, convierte el campo fecha en formato datetime y reordena\n",
    "    \n",
    "    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    df['mes'] = df[columna_fecha].dt.strftime('%m')\n",
    "    df['año'] = df[columna_fecha].dt.strftime('%Y')\n",
    "    df['dia'] = df[columna_fecha].dt.strftime('%d')\n",
    "    df[columna_fecha] = df['año'] + '-' + df['mes']+ '-' + df['dia']\n",
    "    df[columna_fecha] = pd.to_datetime(df[columna_fecha], format = '%Y-%m-%d')\n",
    "    df.sort_values(by=[columna_fecha], inplace = True, ascending = False)\n",
    "    del df['mes']\n",
    "    del df['año']\n",
    "    del df['dia']\n",
    "    \n",
    "    # Deja la nueva columna de fecha en el indice 0 (por motivos de orden de la serie de tiempo)\n",
    "    cols = list(df)\n",
    "    cols.insert(0, cols.pop(cols.index(columna_fecha)))\n",
    "    df = df.loc[:, cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Columna(s) Entero(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enteros(df,_1='cantidad',_2=None):\n",
    "    \n",
    "    campos = [_1,_2]\n",
    "    \n",
    "    for x in campos:\n",
    "        df[x].fillna(0, inplace = True)\n",
    "        df[x] = df[x].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Runners del negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runners(df, semana=False, clasif=False): # semanal: 24. mensual: 12\n",
    "\n",
    "    if semana == False:\n",
    "        df1 = df.groupby(['sku',pd.Grouper(key='fecha', freq='MS')]).sum().reset_index()\n",
    "        ventanas = 12\n",
    "    else:    \n",
    "        df1 = df.groupby(['sku',pd.Grouper(key='fecha', freq='W-MON', label='left',closed='left')]).sum().reset_index()\n",
    "        ventanas = 24\n",
    "        \n",
    "    df1.sort_values(by=['fecha'], ascending=False, inplace=True)\n",
    "    df1['distancia'] = df1['fecha'].diff().dt.days.ne(0).cumsum()\n",
    "    df1['peso'] = round((1/df1['distancia']),2)\n",
    "    df1 = df1[df1['distancia'] <= ventanas]\n",
    "    df1 = df1.groupby(['sku']).sum().reset_index()\n",
    "    \n",
    "    thresh = []\n",
    "    for i in range(1, ventanas+1):\n",
    "        x = 1/i\n",
    "        thresh.append(x)\n",
    "        \n",
    "    x = round(sum(thresh),2)\n",
    "    \n",
    "    clasificacion = []\n",
    "    \n",
    "    for i in range(0,len(df1)):\n",
    "        clas = df1.loc[df1.index[i], 'peso']\n",
    "\n",
    "        if clas < x*0.25:\n",
    "            clas_i = 'LR'\n",
    "        elif (clas >= x*0.25 and clas < x*0.75):\n",
    "            clas_i = 'MR'\n",
    "        elif clas >= x*0.75:\n",
    "            clas_i = 'HR'\n",
    "\n",
    "        clasificacion.append(clas_i)\n",
    "\n",
    "    df1['clasificacion'] = clasificacion\n",
    "    print(df1['clasificacion'].value_counts())\n",
    "    \n",
    "    df1['participacion_Q'] = df1['cantidad'] * df1['peso']\n",
    "    df1['participacion_$'] = (df1['ingreso_neto'] * df1['peso']).astype(int)\n",
    "    \n",
    "    run = df1[['sku','cantidad','ingreso_neto','clasificacion','participacion_Q','participacion_$']]\n",
    "    \n",
    "    if clasif is True:\n",
    "        run = run[['sku','clasificacion']] \n",
    "        df2 = df.merge(run, how='outer').fillna('LR')\n",
    "    else:\n",
    "        df2 = run\n",
    "        \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(df, factor = 2, muestra=10):\n",
    "\n",
    "    df2 = df.groupby(['sku', pd.Grouper(key='fecha', freq='MS')])['cantidad'].sum().reset_index()\n",
    "    df_principal = df2[['fecha', 'sku', 'cantidad']]\n",
    "    df_principal = df2.rename(columns={'cantidad':'total_mes'})\n",
    "    df_principal['mean'] = round(df_principal.groupby(['sku'])['total_mes'].transform('mean'),2)\n",
    "    df_principal['std'] = round(df_principal.groupby(['sku'])['total_mes'].transform('std').fillna(0),2)\n",
    "    \n",
    "    valores = []\n",
    "    df_grafico = pd.DataFrame(np.array([1, 2, 3, 4, 5]), columns=['factor'])\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        \n",
    "        df_principal[f'threshold_{i}'] = (df_principal['mean'] + (i * df_principal['std'])).astype(int)\n",
    "        df_principal[f'diff_{i}'] = (df_principal['total_mes'] - df_principal[f'threshold_{i}']).astype(int)\n",
    "        n_outliers_i = len(df_principal[df_principal[f'diff_{i}'] > 0])\n",
    "        valores.append(n_outliers_i)\n",
    "        \n",
    "    del df_principal['mean'] \n",
    "    del df_principal['std']\n",
    "    \n",
    "    df_grafico['n_outliers'] = valores\n",
    "    print(df_grafico)\n",
    "    \n",
    "    plt.figure(figsize=(13,8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    ax = sns.barplot(x=df_grafico['factor'], y=df_grafico['n_outliers'], palette=\"Blues_r\", alpha=0.8)\n",
    "    for index, row in df_grafico.iterrows():\n",
    "        ax.text(row.name,row.n_outliers, int(row.n_outliers), color='black', ha=\"center\")\n",
    "\n",
    "    df_principal.sort_values(by=[f'diff_{factor}'], ascending=False, inplace=True)\n",
    "    df_principal = df_principal[['fecha','sku','total_mes',f'threshold_{factor}',f'diff_{factor}']]\n",
    "\n",
    "    return df_principal.head(muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Pareto del negocio (Ingresos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_p(df, ag='sku'):\n",
    "    \n",
    "    df1 = df.groupby(ag).sum().reset_index()\n",
    "    total_ingresos = df1['ingreso_neto'].sum()\n",
    "    df1['peso_$ (%)'] = round((df1['ingreso_neto'].div(total_ingresos,axis=0))*100,3)\n",
    "    df1.sort_values(by=['peso_$ (%)'], ascending=False, inplace=True)\n",
    "    df1['acumulado'] = df1['peso_$ (%)'].cumsum()\n",
    "    df2 = df1[df1['acumulado'] <= 80.1]\n",
    "    n_sku_pareto = df2[ag].nunique()\n",
    "    print(f'Número de {ag} que componen el 80% de los ingresos del negocio = {n_sku_pareto}')\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Pareto del negocio (Un. vendidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_q(df, ag='sku'):\n",
    "    \n",
    "    df1 = df.groupby(ag).sum().reset_index()\n",
    "    total_cantidad = df1['cantidad'].sum()\n",
    "    df1['peso_q (%)'] = round((df1['cantidad'].div(total_cantidad,axis=0))*100,3)\n",
    "    df1.sort_values(by=['peso_q (%)'], ascending=False, inplace=True)\n",
    "    df1['acumulado'] = df1['peso_q (%)'].cumsum()\n",
    "    df2 = df1[df1['acumulado'] <= 80.1]\n",
    "    n_sku_pareto = df2[ag].nunique()\n",
    "    print(f'Número de {ag} que componen el 80% de las unidades vendidas del negocio = {n_sku_pareto}')\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Top 10 por agrupación - Cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 por categoria\n",
    "def ventas(df,jerarquia,top=10):\n",
    "    \n",
    "    jer = df.groupby([jerarquia]).sum()\n",
    "    jer = jer.sort_values(by='cantidad',ascending=False)\n",
    "    jer1 = jer.nlargest(top, 'cantidad').reset_index()\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(17,10))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    ax = sns.barplot(x=jer1[jerarquia], y=jer1['cantidad'], order=jer1[jerarquia],palette=\"Blues_r\",alpha=0.8)\n",
    "    for index, row in jer1.iterrows():\n",
    "        ax.text(row.name,row.cantidad, int(row.cantidad), color='black', ha=\"center\")\n",
    "    \n",
    "    jerarquia = jerarquia.capitalize()\n",
    "    plt.title(f\"Top {top} {jerarquia} - Volumen\", fontsize=14)\n",
    "    plt.ylabel(\"Unidades Vendidas\", fontsize=14)\n",
    "    plt.xlabel(f\"{jerarquia}\", fontsize=14)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Top 10 por agrupación - Ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 en ventas (si hay monto facturado)\n",
    "def ingresos(df,jerarquia, top=10):\n",
    "    \n",
    "    jer = df.groupby([jerarquia]).sum()\n",
    "    jer = jer.sort_values(by='ingreso_neto',ascending=False)\n",
    "    jer1 = jer.nlargest(top, 'ingreso_neto').reset_index()\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(17,10))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    ax = sns.barplot(x=jer1[jerarquia], y=jer1['ingreso_neto'], order=jer1[jerarquia],palette=\"Blues_r\",alpha=0.8)\n",
    "    for index, row in jer1.iterrows():\n",
    "        ax.text(row.name,row.ingreso_neto, int(row.ingreso_neto), color='black', ha=\"center\")\n",
    "    \n",
    "    jerarquia = jerarquia.capitalize()\n",
    "    plt.title(f\"Top {top} {jerarquia} - Ingresos Netos\", fontsize=14)\n",
    "    plt.ylabel(\"Monto en $\", fontsize=14)\n",
    "    plt.xlabel(f\"{jerarquia}\", fontsize=14)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Graficar comportamiento total de ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comportamiento total de ventas, según ventana de tiempo, agrupaciones, etc.\n",
    "\n",
    "def graficar_ventas(df, ventana = 'mes', ag = None, ingreso = False, inicio = None, prediccion = None):\n",
    "    \n",
    "    # Formato grafico\n",
    "    sns.set(rc={'figure.figsize':(30,10)})\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    cols = list(df)\n",
    "    del cols[0]\n",
    "    cols.insert(len(df.columns), cols.pop(cols.index('cantidad')))\n",
    "    cols.insert(len(df.columns), cols.pop(cols.index('ingreso_neto')))\n",
    "    df_name = df.loc[:, cols]\n",
    "    \n",
    "    if inicio != None:\n",
    "        df = df[df['fecha'] >= inicio]\n",
    "    \n",
    "    # Selección de la ventana de tiempo para la visualización\n",
    "    if ventana == 'año':\n",
    "        df1 = df.groupby([pd.Grouper(key='fecha', freq= 'Y'), 'id_cliente', 'canal', 'clasificacion', 'sku']).sum().reset_index()\n",
    "    elif ventana == 'semana':\n",
    "        df1 = df.groupby([pd.Grouper(key='fecha', freq='W-MON', label='left',closed='left'), 'id_cliente', 'canal', 'clasificacion','sku']).sum().reset_index()\n",
    "    else:\n",
    "        df1 = df.groupby([pd.Grouper(key='fecha', freq= 'MS'), 'id_cliente', 'canal', 'clasificacion','sku']).sum().reset_index()\n",
    "\n",
    "    # Si se quiere elegir una fecha más adelante de inicio del gráfico\n",
    "    \n",
    "    if prediccion is None:\n",
    "        \n",
    "        # Ver total\n",
    "        if ag is None:\n",
    "            df_grafico = df1\n",
    "        \n",
    "        # Selección de item específico\n",
    "        else:\n",
    "            answer = input(f'¿Qué item quieres ver? (Escribe el nombre exacto): \\n ')\n",
    "            df_grafico = df1[df1[ag] == f'{answer}']\n",
    "        \n",
    "        # Selección de gráfico por ingresos netos\n",
    "        if ingreso == True:\n",
    "            df_grafico = df_grafico.groupby(['fecha'])['ingreso_neto'].sum().reset_index()\n",
    "            df_grafico['promedio_movil_3t'] = df_grafico.ingreso_neto.rolling(3).mean().round(0)\n",
    "            df_grafico['dif'] = df_grafico.ingreso_neto - df_grafico.promedio_movil_3t\n",
    "\n",
    "            #Configuración gráfico\n",
    "            df_grafico.set_index('fecha', inplace=True)\n",
    "            ax = sns.lineplot(data=df_grafico[['ingreso_neto','promedio_movil_3t']])\n",
    "            ax.set_title('Ventas Totales ($)')\n",
    "            ax.set(ylabel='Ingreso Neto ($)')\n",
    "\n",
    "        # Ver total por cantidad\n",
    "        else:\n",
    "            df_grafico = df_grafico.groupby(['fecha'])['cantidad'].sum().reset_index()\n",
    "            df_grafico['promedio_movil_3t'] = df_grafico.cantidad.rolling(3).mean().round(0)\n",
    "            df_grafico['dif'] = df_grafico.cantidad - df_grafico.promedio_movil_3t\n",
    "\n",
    "            #Configuración gráfico\n",
    "            df_grafico.set_index('fecha', inplace=True)\n",
    "            ax = sns.lineplot(data=df_grafico[['cantidad','promedio_movil_3t']])\n",
    "            ax.set_title('Ventas Totales (Q)')\n",
    "            ax.set(ylabel='Unidades')\n",
    "    \n",
    "    else:\n",
    "        if ventana == 'año':\n",
    "            df0 = df1.groupby([pd.Grouper(key='fecha', freq= 'Y'), 'sku']).sum().reset_index()\n",
    "        elif ventana == 'semana':\n",
    "            df0 = df1.groupby([pd.Grouper(key='fecha', freq='W-MON', label='left',closed='left'), 'sku']).sum().reset_index()\n",
    "        else:\n",
    "            df0 = df1.groupby([pd.Grouper(key='fecha', freq= 'MS'), 'sku']).sum().reset_index()\n",
    "        \n",
    "        \n",
    "        df0.rename(columns={'fecha': 'date','cantidad':'hist', ag: 'item'}, inplace=True)\n",
    "        \n",
    "        df2 = df0.copy()\n",
    "\n",
    "        df3 = prediccion[['date', 'item','hist','pred','upper','lower']]\n",
    "        \n",
    "        if ag is None:\n",
    "            df_trs = df2\n",
    "            df_pred = df3\n",
    "        \n",
    "        else:\n",
    "            answer = input(f'¿Qué item quieres ver? (Escribe el nombre exacto): \\n ')\n",
    "            df_trs = df2[df2['item'] == f'{answer}']\n",
    "            df_pred = df3[df3['item'] == f'{answer}']\n",
    "        \n",
    "        merged = df_trs.merge(df_pred, how='outer')\n",
    "        df_grafico = merged[['date','item','hist','pred','upper','lower']]\n",
    "        df_grafico = df_grafico.groupby(['date']).sum().reset_index()\n",
    "        df_grafico['diff'] = df_grafico['hist'] - df_grafico['pred']\n",
    "        df_grafico.set_index('date', inplace=True)\n",
    "        ax = sns.lineplot(data=df_grafico[['hist','pred','upper','lower']])\n",
    "        ax.set_title('Ventas Totales + Prediccion')\n",
    "        ax.set(ylabel='Unidades')\n",
    "        return df_grafico.tail(12)\n",
    "    \n",
    "    \n",
    "    # Título del eje X\n",
    "    if ag == None:\n",
    "        ax.set(xlabel='Total')\n",
    "    else:\n",
    "        ax.set(xlabel=f'{answer}')\n",
    "    \n",
    "    ax.set(ylim=0)\n",
    "    \n",
    "    return df_grafico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Métricas Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para calcular smape individual por ventana de tiempo + otros cálculos generales, uniendo archivo de inferencias (v0.2) con transaccional\n",
    "\n",
    "def metricas_error(df,inferencia='inference.csv', semanal = False, agrupacion=None):\n",
    "\n",
    "    # importar archivo inferencias\n",
    "    inferencia = pd.read_csv(inferencia)\n",
    "    inferencia.sort_values(by=['item','date'], ascending=True, inplace=True)\n",
    "    inferencia['date'] = pd.to_datetime(inferencia['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    # adaptar transaccional\n",
    "\n",
    "    # Caso Mensual\n",
    "    if semanal == False:\n",
    "        \n",
    "        # Agrupacion solo por sku\n",
    "        if agrupacion == None:\n",
    "            \n",
    "            transaccional = df.groupby([pd.Grouper(key='fecha', freq='MS'), 'sku']).sum()\n",
    "            transaccional.reset_index(drop=False, inplace=True)\n",
    "            transaccional.sort_values(by=['sku','fecha'], ascending=True, inplace=True)\n",
    "        \n",
    "        # Agrupacion además de sku\n",
    "        else:\n",
    "            transaccional = df.groupby([pd.Grouper(key='fecha', freq='MS'), 'sku']).sum()\n",
    "            transaccional.reset_index(drop=False, inplace=True)\n",
    "            transaccional.sort_values(by=[agrupacion,'sku','fecha'], ascending=True, inplace=True)\n",
    "            transaccional[\"item\"] = transaccional[agrupacion].astype(str) + '|' + transaccional[\"sku\"].astype(str)\n",
    "            del transaccional['sku']\n",
    "            del transaccional[agrupacion]\n",
    "        \n",
    "    # Caso semanal\n",
    "    else:\n",
    "        \n",
    "        # Agrupacion solo por sku\n",
    "        if agrupacion == None:\n",
    "            \n",
    "            transaccional = df.groupby([pd.Grouper(key='fecha', freq='W-MON', label='left',closed='left'), 'sku']).sum()\n",
    "            transaccional.reset_index(drop=False, inplace=True)\n",
    "            transaccional.sort_values(by=['sku','fecha'], ascending=True, inplace=True)\n",
    "        \n",
    "        # Agrupacion además de sku\n",
    "        else:\n",
    "            transaccional = df.groupby([pd.Grouper(key='fecha', freq='W-MON', label='left',closed='left'), agrupacion,'sku']).sum()\n",
    "            transaccional.reset_index(drop=False, inplace=True)\n",
    "            transaccional.sort_values(by=[agrupacion,'sku','fecha'], ascending=True, inplace=True)\n",
    "            transaccional[\"item\"] = transaccional[agrupacion].astype(str) + '|' + transaccional[\"sku\"].astype(str)\n",
    "            del transaccional['sku']\n",
    "            del transaccional[agrupacion]\n",
    "        \n",
    "    # Cambio de nombre de columnas y reordenamiento para coincidir con dataframe de inferencias   \n",
    "    transaccional.rename(columns={'sku' : 'item', 'fecha': 'date'}, inplace= True)\n",
    "    transaccional = transaccional[['date', 'item', 'cantidad']]\n",
    "    \n",
    "    # unión transaccional con inferencias\n",
    "    merged=pd.merge(transaccional,inferencia, how='outer')\n",
    "    merged.sort_values(by=['item','date'], ascending=True, inplace=True)\n",
    "    merged = merged.rename(columns={'cantidad' : 'hist', 'units': 'pred'}).fillna(0)\n",
    "    merged = merged[(merged.date <= max(inferencia['date'])) & (merged.date >= min(inferencia['date']))]\n",
    "    \n",
    "    # construcción de métricas\n",
    "    smape = []\n",
    "    accuracy = []\n",
    "    mape = []\n",
    "    bias = []\n",
    "    hist_pred = []\n",
    "    hist_pred2 = []\n",
    "    \n",
    "    for i in range(0,len(merged)):\n",
    "        hist = merged.loc[merged.index[i],'hist'].astype(int)\n",
    "        pred = merged.loc[merged.index[i],'pred']\n",
    "\n",
    "        hist_pred_i = ((hist) - pred)\n",
    "        hist_pred_i2 = ((hist) - pred)**2\n",
    "        hist_pred.append(hist_pred_i)\n",
    "        hist_pred2.append(hist_pred_i2)\n",
    "\n",
    "        if pred != 0:\n",
    "            bias_i = round((((hist)/pred)-1),5)\n",
    "        else:\n",
    "            bias_i = -1\n",
    "        \n",
    "        bias.append(bias_i)\n",
    "\n",
    "        if abs(hist_pred_i) > 0.05:\n",
    "            smape_i = 100*((abs(hist_pred_i)/((abs(hist) + abs(pred))/2)))\n",
    "        else:\n",
    "            smape_i = 0\n",
    "            \n",
    "        smape.append(smape_i)\n",
    "            \n",
    "        if hist != 0:\n",
    "            accuracy_i = (1-(abs(hist_pred_i)/(hist)))*100\n",
    "        else:\n",
    "            accuracy_i = 0\n",
    "        \n",
    "        accuracy.append(accuracy_i)\n",
    "           \n",
    "            \n",
    "    # smape\n",
    "    merged['smape1'] = smape\n",
    "    \n",
    "    # forecast accuracy\n",
    "    merged['accuracy1'] = accuracy\n",
    "\n",
    "    # bias\n",
    "    merged['bias1'] = bias\n",
    "    \n",
    "    # diferencia absoluta entre historico e inferencia\n",
    "    merged['hist_pred'] = hist_pred\n",
    "    merged['rmse1'] = abs(merged['hist_pred'])\n",
    "    merged['hist_pred2'] = hist_pred2\n",
    "    del merged['hist_pred']\n",
    "    \n",
    "    merged = merged[['date','model','item', 'hist','pred','lower','upper','rmse','rmse1','smape','smape1','accuracy','accuracy1','bias','bias1','hist_pred2']]\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Sobrepronósticos y Subpronósticos en dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se asigna datafame e índice de la columna con \"bias1\" para revisar cuántos items fueron sobre o sub pronosticados\n",
    "\n",
    "def nivel_stock(df):\n",
    "\n",
    "    quiebre = []\n",
    "    exceso = []\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "        bias_i = df.loc[df.index[i], 'bias1']\n",
    "\n",
    "        if bias_i > 0:\n",
    "            quiebre.append(bias_i)\n",
    "        else:\n",
    "            exceso.append(bias_i)\n",
    "\n",
    "    nq = len(quiebre)\n",
    "    ne = len(exceso)\n",
    "    total = nq + ne\n",
    "    nqt = round((nq/total)*100,2)\n",
    "    net = round((ne/total)*100,2)\n",
    "\n",
    "    return print(f'Numero de items sobrepronosticados: {ne} ({net}%)\\n'\n",
    "                 f'Numero de items subpronosticados: {nq} ({nqt}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Resumen Inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para calcular a nivel de sku o ventana de tiempo smape promedio, bias y forecast accuracy\n",
    "\n",
    "def resumen_inferencias(df, grupo='item'):\n",
    "    \n",
    "    resultados = df.groupby([grupo]).agg({'hist':'sum','pred':'sum','rmse':np.mean,'upper':'sum','lower':'sum','rmse1':'sum','accuracy':np.mean,'hist_pred2':np.mean}).reset_index()\n",
    "    resultados['smape'] = round(df.groupby([grupo]).agg({'smape':np.mean}),2).reset_index().drop([grupo], axis=1)\n",
    "    resultados['smape1'] = round(df.groupby([grupo]).agg({'smape1':np.mean}),2).reset_index().drop([grupo], axis=1)\n",
    "    resultados['hist_pred_abs'] = resultados['rmse1']\n",
    "    resultados['rmse1'] = round((resultados['hist_pred2']**0.5),2)\n",
    "    resultados['accuracy1'] = round((1 - (resultados['hist_pred_abs'] / resultados['hist'])),2).replace([np.inf, -np.inf], 4)\n",
    "    resultados['bias'] = df.groupby([grupo]).agg({'bias':np.mean}).reset_index().drop([grupo], axis=1)\n",
    "    resultados['bias1'] = round(((resultados['hist'] / resultados['pred']) - 1),2)\n",
    "    resultados['hist_pred2']\n",
    "    \n",
    "    resultados = resultados[[grupo, 'hist','pred','upper','lower','hist_pred_abs','rmse','rmse1','smape','smape1','accuracy','accuracy1','bias','bias1','hist_pred2']]\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función: Métricas Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_globales(df):\n",
    "    sum_hist = df['hist'].sum()\n",
    "    sum_pred = df['pred'].sum()\n",
    "    sum_hist_pred = df['hist_pred_abs'].sum()\n",
    "    mean_hist_pred2 = df['hist_pred2'].mean()\n",
    "    hist_pred2 = []\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        hist = df.loc[df.index[i], 'hist']\n",
    "        pred = df.loc[df.index[i], 'pred']\n",
    "        \n",
    "        dif = (hist - pred)**2\n",
    "        hist_pred2.append(dif)\n",
    "    \n",
    "    rmse = round((sum(hist_pred2) / len(hist_pred2))**0.5,2)\n",
    "    rmse1 = round(df['rmse'].mean(),2)\n",
    "    rmse2 = round(df['rmse1'].mean(),2)\n",
    "    smape = round(df['smape'].mean(),3)\n",
    "    smape1 = round(df['smape1'].mean(),3)\n",
    "    accuracy = round(1 - (sum_hist_pred/sum_hist),3)*100\n",
    "    accuracy1 = round(df['accuracy'].mean(),3)\n",
    "    accuracy2 = round(df['accuracy1'].mean(),3)\n",
    "    bias = round((sum_hist/sum_pred) - 1,3)\n",
    "    bias1 = round(df['bias'].mean(),3)\n",
    "    bias2 = round(df['bias1'].mean(),3)\n",
    "    \n",
    "    print(f'RMSE = {rmse} ; {rmse1} ; {rmse2}\\n'\n",
    "         f'SMAPE = {smape} ; {smape1}\\n'\n",
    "         f'FA = {accuracy}% ; {accuracy1}% ; {accuracy2}%\\n'\n",
    "         f'Bias = {bias} ; {bias1} ; {bias2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Partir Aquí!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para importar archivo excel y asignar a dataframe \"orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = importar_excel('ruta de acceso archivo excel', xlsx=False);orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar archivo .csv y asignar a dataframe \"orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = pd.read_csv('ruta de acceso archivo .csv',\n",
    "                   delimiter=',',low_memory=False);orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para un resumen del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para unir verticalmente dos dataframes con los mismos campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para unir verticalmente dos dataframes\n",
    "trs = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para filtrar un dataframe usando otro con las características, y crear nuevo dataframe con filtro aplicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para unir dos dataframes con columna en comun\n",
    "common = trs.merge(df_filtro,on=['campo_en_comun'])\n",
    "df_filtrado = trs[(df.material.isin(common.campo_en_comun))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para filtrar un dataframe y solo ver un SKU en específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs[trs['sku'] == 10001266]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para armar dataframe transaccional \"trs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = esquema_transaccional(orig,[0,1,2,3,4,5]);trs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para revisar registros con celdas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos(trs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para revisar y/o eliminar registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados(trs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para crear y/o formatear campo de fecha en transaccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = col_fecha(trs,'fecha');trs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para formatear en enteros el/los campo(s) con valores a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = enteros(trs,'cantidad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para detectar High, Medium y Low Runners del negocio, para últimos 12 meses o 24 semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners(trs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para ver nº de outliers según factor, dataframe con factor elegido y gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers(df, factor = 2, muestra = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar mensualmente las ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trsmes = trs.groupby([pd.Grouper(key='fecha', freq='MS'),'id_cliente','canal','sku']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para armar dataframe con el pareto del negocio, asignar a dataframe para ver resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_p = pareto_p(trs, ag='sku')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para armar dataframe con el pareto del negocio, asignar a dataframe para ver resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_q = pareto_q(trs, ag='sku')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordena de menor a mayor (True) y viceversa las unidades vendidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs.sort_values(by=['cantidad'], ascending=True, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para graficar top 10 - Cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas(trs,'jerarquia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para graficar top 10 - Ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingresos(trs,'canal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para graficar ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_ventas(trs, ag='sku',ventana='mes',inicio=None,ingreso=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Al terminar de procesar transaccional, exportar dataframe a archivo .csv (UTF-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exportar dataframe de transaccional a un csv\n",
    "trs.to_csv(r'/ruta_de_archivo/titulo_archivo_transaccional.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Proceso: Transaccional + Inferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para unir transaccional con inferencias + cálculo métricas, asignar a dataframe \"inf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = metricas_error(trs,\n",
    "                     'ruta de acceso archivo inferencia',\n",
    "                     semanal=False,\n",
    "                     ag2='tienda');inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para mostrar total de predicciones por arriba y debajo, junto con %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nivel_stock(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para calcular métricas a nivel de agrupación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = resumen_inferencias(inf);item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_o_semana = resumen_inferencias(inf,grupo='date');mes_o_semana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar función para calcular métricas a nivel de modelo (globales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_globales(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar SMAPE para periodo pronósticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico smape 2\n",
    "sns.histplot(data=inf['smape1'], kde=True,binwidth=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar Forecast Accuracy por ventana de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico forecast accuracy\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "sns.lineplot(data=inf[['date','accuracy']].set_index('date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar venta promedio vs predicción promedio por ventana de tiempo + intervalos 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico venta vs prediccion\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "sns.lineplot(data=inf[['date','hist','pred']].set_index('date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar RMSE vs SMAPE vs Volumen ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico rmse vs smape vs volumen\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1 = item[item['rmse1'] <=5000].plot.scatter(x='smape1', y='rmse', c='hist', colormap='plasma',figsize=(20,15), legend = True,logy=True, ax=ax1)\n",
    "ax1.set_xlabel(\"smape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
